version: 2.1

executors:
  linux-self-hosted:
    machine:
      enabled: true
    resource_class: virus/windows 

jobs:
  build:
    executor: linux-self-hosted
    steps:
      - checkout
      - run:
          name: Build Docker Image
          command: |
            docker build -t $ECR_REPOSITORY:latest .
  
  push-to-ecr:
    executor: linux-self-hosted
    steps:
      - checkout
      - run:
          name: Authenticate with ECR
          command: |
            aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin $ECR_REGISTRY
      - run:
          name: Build, Tag, and Push Docker Image to ECR
          command: |
            IMAGE_TAG="v1.0.${CIRCLE_BUILD_NUM}"
            echo "export IMAGE_TAG=$IMAGE_TAG" >> $BASH_ENV
            docker build -t $ECR_REPOSITORY:$IMAGE_TAG .
            docker tag $ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
            docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG

  deploy-to-eks:
    executor: linux-self-hosted
    steps:
      - checkout
      - run:
          name: Install kubectl if not available
          command: |
            if ! command -v kubectl &> /dev/null; then
              echo "Installing kubectl..."
              VERSION=$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)
              curl -LO https://dl.k8s.io/release/${VERSION}/bin/linux/amd64/kubectl
              chmod +x kubectl
              mkdir -p $HOME/bin
              mv kubectl $HOME/bin/kubectl
              echo 'export PATH=$HOME/bin:$PATH' >> $BASH_ENV
            else
              echo "kubectl already installed"
            fi
      - run:
          name: Load env + Set up kubeconfig
          shell: /bin/bash -eo pipefail
          command: |
            # Directly export env vars instead of sourcing $BASH_ENV
            aws sts get-caller-identity
            echo "Using AWS Region: $AWS_REGION"
            echo "Using EKS Cluster Name: $EKS_CLUSTER_NAME"
            if ! aws eks --region $AWS_REGION update-kubeconfig --name $EKS_CLUSTER_NAME; then
              echo "Failed to update kubeconfig. Check AWS credentials and EKS cluster name."
              exit 1
            fi
            kubectl config view --minify
      - run:
          name: Export IMAGE_TAG for deployment
          command: |
            IMAGE_TAG="v1.0.${CIRCLE_BUILD_NUM}"
            echo "export IMAGE_TAG=$IMAGE_TAG" >> $BASH_ENV
      - run:
          name: Check Kubernetes manifests exist
          command: |
            source $BASH_ENV
            echo "Checking for deployment.yaml and service.yaml in root directory..."
            ls -la
            test -f deployment.yaml || (echo "Error: deployment.yaml not found" && exit 1)
            test -f service.yaml || (echo "Error: service.yaml not found" && exit 1)
      - run:
          name: Deploy to EKS
          command: |
            source $BASH_ENV
            echo "Current kubectl context:"
            kubectl config current-context
            echo "Verifying cluster connectivity:"
            kubectl get nodes || echo "Failed to connect to cluster nodes!"
            echo "Deploying to Kubernetes..."
            if ! envsubst < deployment.yaml | kubectl apply -f -; then
              echo "Failed to apply deployment.yaml"
              exit 1
            fi
            if ! kubectl apply -f service.yaml; then
              echo "Failed to apply service.yaml"
              exit 1
            fi
            echo "Deployment successful!"

workflows:
  version: 2
  deploy-pipeline:
    jobs:
      - build
      - push-to-ecr:
          requires:
            - build
      - deploy-to-eks:
          requires:
            - push-to-ecr
